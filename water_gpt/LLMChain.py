import requests
from langchain import PromptTemplate, LLMChain
import asyncio
import json
from langchain.llms.base import LLM
from datetime import datetime

API_URL = "http://4090p8000.huannago.com/v1/chat/completions"
WATER_OUTAGE_URL = "http://localhost:8002/water-outage-query"
EMBEDDING_URL = "http://3090p8001.huannago.com/embedding"
HEADERS = {"Content-Type": "application/json", "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36 Edg/136.0.0.0"}
MODEL   = "gpt-3.5-turbo"


class ClassifierLLM(LLM):
    @property
    def _llm_type(self) -> str:
        return "custom"

    def _call(self, prompt: str, stop=None) -> str:
        payload = {
            "model":    MODEL,
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹è¨Šæ¯åˆ†é¡å™¨ï¼Œåªå›è¦†å–®å­— \"æ˜¯\" æˆ– \"å¦\""},
                {"role": "user",   "content": prompt}
            ],
            "stream": False
        }
        resp = requests.post(API_URL, headers=HEADERS, json=payload)
        resp.raise_for_status()
        data = resp.json()
        return data["choices"][0]["message"]["content"]

    @property
    def identifying_params(self) -> dict:
        return {"model": MODEL}

class StatusLLM(ClassifierLLM):  # å¯ç¹¼æ‰¿åŒæ¨£åº•å±¤
    def _call(self, prompt: str, stop=None) -> str:
        system_prompt = """ä½ æ˜¯ä¸€å€‹ç‹€æ…‹é¸æ“‡å™¨ï¼Œè² è²¬æ ¹æ“šè¼¸å…¥çš„å°è©±ç´€éŒ„åˆ¤æ–·ç•¶å‰çš„æ„åœ–ç‹€æ…‹ã€‚ä½ çš„ä»»å‹™æ˜¯åˆ†æå°è©±å…§å®¹ï¼Œä¸¦å¾ä»¥ä¸‹ä¸‰ç¨®ç‹€æ…‹ä¸­é¸æ“‡ä¸€å€‹ä½œç‚ºç•¶å‰æ„åœ–ï¼š
READYï¼šæ­£å¸¸å°è©±ï¼Œç„¡ç‰¹å®šæ„åœ–æˆ–æœªé€²å…¥ç‰¹å®šåŠŸèƒ½æµç¨‹ã€‚
OUTAGEï¼šæŸ¥è©¢å³æ™‚åœæ°´è³‡è¨Šï¼Œç•¶ç”¨æˆ¶æåŠåœæ°´ç›¸é—œå•é¡Œæˆ–æŸ¥è©¢æ™‚é€²å…¥æ­¤ç‹€æ…‹ã€‚
RAGï¼šä¸€èˆ¬ FAQï¼Œç•¶ç”¨æˆ¶æå‡ºå¸¸è¦‹å•é¡Œæˆ–å°‹æ±‚ä¸€èˆ¬è³‡è¨Šæ™‚é€²å…¥æ­¤ç‹€æ…‹ã€‚

è¦å‰‡ï¼š
ç‹€æ…‹ç¸½æ˜¯æ ¹æ“šç”¨æˆ¶æœ€æ–°ä¸€å‰‡è¨Šæ¯çš„æ„åœ–ä¾†åˆ¤æ–·ï¼ˆä¸è€ƒæ…®åŠ©ç†ç•¶å‰æµç¨‹ï¼‰ï¼Œåªè¦ç”¨æˆ¶å•äº†æ–°å•é¡Œï¼Œå°±ä»¥æ–°å•é¡Œç‚ºæº–ã€‚
è‹¥ç”¨æˆ¶æœ€å¾Œè¨Šæ¯æ˜¯åœæ°´æŸ¥è©¢ï¼ˆå«ã€Œåœæ°´è³‡è¨Šã€ã€ã€Œæœ‰æ²’æœ‰åœæ°´ã€ã€ã€ŒæŸ¥åœæ°´ã€ç­‰ï¼‰ï¼Œå‰‡ç‚º OUTAGEã€‚
è‹¥ç”¨æˆ¶æœ€å¾Œè¨Šæ¯æ˜¯ä¸€èˆ¬å•é¡Œï¼ˆå¦‚ã€Œå¦‚ä½•ç¹³æ°´è²»ã€ç­‰éåœæ°´ç›¸é—œï¼‰ï¼Œå‰‡ç‚º RAGã€‚
è‹¥æœ€å¾Œè¨Šæ¯ç„¡æ˜ç¢ºæ„åœ–ï¼ˆå¦‚å¯’æš„ï¼‰ï¼Œå‰‡ç‚º READYã€‚
è‹¥æœ€å¾Œè¨Šæ¯æ„åœ–ä¸æ˜ï¼Œå‰‡å»¶çºŒä¸Šä¸€å€‹æ˜ç¢ºç‹€æ…‹ã€‚

ç¯„ä¾‹ï¼š
ç”¨æˆ¶æœ€å¾Œè©¢å•ã€Œå¦‚ä½•ç¹³æ°´è²»ï¼Ÿã€â†’ {"status": "RAG"}
ç”¨æˆ¶æœ€å¾Œè©¢å•ã€Œé€™è£¡æœ‰åœæ°´å—ï¼Ÿã€â†’ {"status": "OUTAGE"}
ç”¨æˆ¶æœ€å¾Œèªªã€Œä½ å¥½ã€â†’ {"status": "READY"}

è«‹æ ¹æ“šä»¥ä¸Šè¦å‰‡åˆ†æä»¥ä¸‹å°è©±ç´€éŒ„ä¸¦è¼¸å‡ºçµæœã€‚"""

        payload = {
            "model":    MODEL,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user",   "content": prompt}
            ],
            "stream": False
        }
        resp = requests.post(API_URL, headers=HEADERS, json=payload)
        resp.raise_for_status()
        data = resp.json()
        return data["choices"][0]["message"]["content"]

class RetrieveLLM(ClassifierLLM):  # å¯ç¹¼æ‰¿åŒæ¨£åº•å±¤
    def _call(self, prompt: str, stop=None) -> str:
        payload = {
            "model":    MODEL,
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹æ–‡ä»¶ç‰‡æ®µé¸æ“‡å™¨ï¼Œåªå›è¦†æ–‡ä»¶ç‰‡æ®µæ‰€å±¬çš„ç·¨è™Ÿ"},
                {"role": "user",   "content": prompt}
            ],
            "stream": False
        }
        resp = requests.post(API_URL, headers=HEADERS, json=payload)
        resp.raise_for_status()
        data = resp.json()
        return data["choices"][0]["message"]["content"]


class EmotionLLM(ClassifierLLM):  # å¯ç¹¼æ‰¿åŒæ¨£åº•å±¤
    def _call(self, prompt: str, stop=None) -> str:
        system_prompt = """æ‚¨æ˜¯ä¸€å€‹é«˜åº¦å°ˆæ¥­çš„æƒ…ç·’è¾¨è­˜é›·é”ã€‚æƒ…å¢ƒæ˜¯ä¸€ä½å°ˆæ¥­ä¿éšªæ¥­å‹™å“¡çš„å°è©±æ–‡æœ¬ï¼Œæ‚¨çš„ä»»å‹™æ˜¯åˆ†æè¼¸å…¥çš„æ–‡æœ¬ï¼Œè«‹åš´æ ¼éµå®ˆä»¥ä¸‹æŒ‡å—:

1. æƒ…ç·’é¡åˆ¥å®šç¾©:
  - åˆ†æè¼¸å…¥çš„æ–‡æœ¬ä¸¦æ­¸é¡ç‚ºä»¥ä¸‹5ç¨®æƒ…ç·’ä¹‹ä¸€:anger, irritation, uncertainty, happiness, neutral
  **anger**æ–‡æœ¬å¸¶æœ‰ç›´è¦ºä¸”å¼·çƒˆçš„è² é¢æªè¾­:
    - é«’è©±æˆ–æ¥µåº¦è² é¢çš„æªè¾­ã€‚
    - é‡å°æ€§å«æ„æˆ–æƒ¡è¨€ç›¸å‘çš„æªè¾­ã€‚
    - ä¾®è¾±æ€§çš„äººèº«æ”»æ“Šæªè¾­ã€‚

  **irritation**æ–‡æœ¬å¸¶æœ‰è¼•åº¦çš„è² é¢å«æ„:
    - ä¸è€ç…©ã€å­ç…©ã€‚
    - æŒ–è‹¦ã€å˜²è«·ã€è«·åˆºã€‚
    - å§”å©‰æˆ–é–“æ¥çš„è² é¢è©±èªã€‚
    - çµ•å°ä¸æœƒå‡ºç¾ç›´è¦ºçš„ã€æ˜ç¢ºæŒ‡åçš„æ”»æ“Šæªè¾­ã€‚
    - æœªé”åˆ°"anger"çš„ç¨‹åº¦ã€‚

  **uncertainty**æ–‡æœ¬å¸¶æœ‰ä¸ç¢ºå®šçš„æ…‹åº¦:
    - æ¨¡ç³Šä¸å®šã€çŒ¶è±«ã€ç–‘æƒ‘ã€‚
    - äº‹ä»¶æŒæ¡ç¨‹åº¦ä¸è¶³ã€‚
    - å¾…ç¢ºèªã€‚
    - çµ•å°ä¸æœƒå‡ºç¾è©¢å•ä»–äººè³‡è¨Šæˆ–æ„è¦‹ã€‚

  **happiness**æ–‡æœ¬å¸¶æœ‰å¿«æ¨‚çš„æ…‹åº¦:
    - ç¨±è®šæˆ–è®šç¾å°æ–¹ã€‚
    - æ„Ÿè¬å°æ–¹ã€‚
    - èªåŒå°æ–¹è§€é»æˆ–è¡Œç‚ºã€‚
    - è¡¨é”å°äº‹ä»¶çš„æ»¿æ„èˆ‡å–œæ‚…ã€‚

  **neutral**æ–‡æœ¬æ²’æœ‰æ˜ç¢ºçš„æƒ…ç·’å‚¾å‘:
    - é™³è¿°äº‹å¯¦ã€‚
    - æ•˜äº‹å¥ã€‚
    - ä½¿ç”¨ç¦®è²Œèªè¨€ã€‚
    - èªæ°£å†·éœä¸”å¹³è¡¡ã€‚
    - è©¢å•ä»–äººè³‡è¨Šæˆ–æ„è¦‹ã€‚

2. é—œéµè©åŒ¹é…èˆ‡èªå¢ƒè¦å‰‡ï¼š
  - uncertaintyï¼šé—œéµè©åŒ…æ‹¬ã€Œæ‡‰è©²ã€ã€ã€Œä¸ç¢ºå®šã€ã€ã€Œä¸çŸ¥é“ã€ã€ã€ŒæŸ¥ä¸€ä¸‹ã€ã€ã€Œå¥½åƒã€ã€ã€Œæ™šé»å†ç¢ºèªã€ã€‚  
  - neutralï¼šé—œéµè©åŒ…æ‹¬ã€Œæœ€ä½æŠ•ä¿é‡‘é¡ã€ã€ã€Œæœ€é«˜ä¿é¡ã€ã€ã€Œæˆ‘å€‘çš„ä¿è²»ã€ã€‚  
  - irritationï¼šé—œéµè©åŒ…æ‹¬ã€Œä¹‹å‰ã€ã€ã€Œä¸èƒ½ã€ã€ã€Œå¥½å¥½è¨˜ä¸‹ä¾†ã€ã€ã€Œå‰›å‰›æœ‰èªªäº†ã€ï¼Œæˆ–è«·åˆºæ€§è¡¨é”ã€‚  
  - angerï¼šé—œéµè©åŒ…æ‹¬ã€Œç¬¨ã€ã€ã€Œä½ å¾ˆç¬¨ã€ã€ã€Œçµ¦æˆ‘æ»¾ã€ã€ã€Œä½ å¾ˆè‡ªç§ã€ã€‚  
  - happinessï¼šé—œéµè©åŒ…æ‹¬ã€Œå¾ˆé«˜èˆˆã€ã€ã€Œå¾ˆæ¨‚æ„ã€ã€ã€Œè¬è¬ã€ã€ã€Œå¾ˆé–‹å¿ƒã€ã€ã€Œæ‚¨çœŸå°ˆæ¥­ã€ã€ã€Œæ‚¨çœŸå…§è¡Œã€ã€ã€Œæ‚¨çœŸè°æ˜ã€ã€‚  

3. æ³¨æ„äº‹é …:
   - ä¿æŒå®¢è§€ï¼Œä¸è¦è¢«æ–‡æœ¬çš„å…§å®¹å½±éŸ¿æ‚¨çš„åˆ¤æ–·ã€‚
   - è€ƒæ…®æ–‡åŒ–å’Œèªå¢ƒå› ç´ ï¼Œä½†å§‹çµ‚ä¿æŒä¸€è‡´çš„åˆ†é¡æ¨™æº–ã€‚
   - å¦‚é‡åˆ°æ¨¡æ£±å…©å¯çš„æƒ…æ³ï¼Œé¸æ“‡æœ€é©åˆçš„å–®ä¸€æ¨™ç±¤ã€‚
   - è‹¥åŒ¹é…åˆ°é—œéµå­—ï¼Œå‰‡æ­¸ç´è‡³å°æ‡‰æƒ…ç·’ã€‚
   - è‚¯å®šå°æ–¹é€šå¸¸æ˜¯happinessã€‚

4. è¼¸å‡ºæ ¼å¼:
   - åƒ…è¼¸å‡ºä¸€å€‹æƒ…ç·’æ¨™ç±¤ï¼Œä¸éœ€è¦è§£é‡‹æˆ–å…¶ä»–é¡å¤–ä¿¡æ¯ã€‚
   - ç¢ºä¿è¼¸å‡ºçš„æ¨™ç±¤ç‚ºå°å¯«ã€‚

è«‹æ ¹æ“šä»¥ä¸ŠæŒ‡å—,æº–ç¢ºåœ°å°‡è¼¸å…¥æ–‡æœ¬æ­¸é¡ç‚º5ç¨®æƒ…ç·’ä¹‹ä¸€ã€‚"""

        payload = {
            "model":    MODEL,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user",   "content": prompt}
            ],
            "stream": False
        }
        resp = requests.post(API_URL, headers=HEADERS, json=payload)
        resp.raise_for_status()
        data = resp.json()
        return data["choices"][0]["message"]["content"]

class LocationOutageLLM(ClassifierLLM):
    def _call(self, prompt: str, stop=None) -> str:
        system_prompt = """ä½ æ˜¯ä¸€å€‹åœ°é»æ•æ‰å™¨ï¼Œåˆ¤æ–·ä½¿ç”¨è€…è¼¸å…¥çš„å…§å®¹æ‰€åŒ…å«çš„åœ°é»ã€‚
ã€åˆ¤æ–·æ¢ä»¶ã€‘éœ€åŒæ™‚ç¬¦åˆï¼š
1. è¨Šæ¯ä¸­å¿…é ˆæ˜ç¢ºæåŠå°ç£åœ°åï¼ˆç”±ä½¿ç”¨è€…è¼¸å…¥ç›´æ¥æåˆ°ï¼‰ï¼Œåœ°åå¯åˆ†ç‚ºï¼š
   - Countiesï¼šä¸€ã€äºŒç´šè¡Œæ”¿å€ï¼ˆå¦‚ã€Œè‡ºä¸­å¸‚ã€ã€ã€Œå—æŠ•ç¸£ã€ï¼‰
   - Townsï¼šä¸‰ç´šè¡Œæ”¿å€ï¼ˆå¦‚ã€ŒåŒ—å€ã€ã€ã€ŒåŸ”é‡Œé®ã€ï¼‰
   å¦‚æœæåŠåˆ°å¤šå€‹ä¸€ã€äºŒç´šè¡Œæ”¿å€ï¼Œå‰‡æ“·å–é¦–å€‹ã€‚
   å¦‚æœæåŠåˆ°å¤šå€‹ä¸‰ç´šè¡Œæ”¿å€ï¼Œå‰‡æ“·å–é¦–å€‹ã€‚
   å¦‚æœåªæåŠä¸‰ç´šè¡Œæ”¿å€ï¼Œå‰‡è‡ªå‹•è£œå…¨å…¶æ‰€å±¬çš„ä¸€ã€äºŒç´šè¡Œæ”¿å€ã€‚
   å¦‚æœæåŠä¸‰ç´šè¡Œæ”¿å€ä¸åœ¨å…¶æ‰€å±¬çš„ä¸€ã€äºŒç´šè¡Œæ”¿å€ï¼Œå‰‡è¦–ç‚ºç„¡æ•ˆã€‚
   åœ°åå¿…é ˆåœ¨åœ°åè³‡æ–™åº«ä¸­å­˜åœ¨ï¼Œå¦å‰‡ç¦æ­¢è¼¸å‡ºã€‚

   - åœ°åè³‡æ–™åº«ï¼š
[åŸºéš†å¸‚]
ä¸­æ­£å€, ä¸­å±±å€, ä¿¡ç¾©å€, ä»æ„›å€, æš–æš–å€, å®‰æ¨‚å€, ä¸ƒå µå€

[æ–°åŒ—å¸‚]
äº”è‚¡å€, å…«é‡Œå€, æ·¡æ°´å€, ä¸‰èŠå€, çŸ³é–€å€, æ—å£å€, ä¸‰é‡å€, è˜†æ´²å€, é‡‘å±±å€, æ±æ­¢å€, è¬é‡Œå€, ä¸‰å³½å€, é¶¯æ­Œå€, ç‘èŠ³å€, çŸ³ç¢‡å€, å¹³æºªå€, é›™æºªå€, è²¢å¯®å€, åªæ—å€, ä¸­å’Œå€, æ°¸å’Œå€, æ¿æ©‹å€, æ¨¹æ—å€, æ–°èŠå€, æ–°åº—å€, åœŸåŸå€, çƒä¾†å€, æ³°å±±å€, æ·±å‘å€

[æ¡ƒåœ’å¸‚]
é¾æ½­å€, å¹³é®å€, å¤§æºªå€, å…«å¾·å€, ä¸­å£¢å€, å¾©èˆˆå€, æ–°å±‹å€, æ¥Šæ¢…å€, é¾œå±±å€, æ¡ƒåœ’å€, è˜†ç«¹å€, å¤§åœ’å€, è§€éŸ³å€

[æ–°ç«¹å¸‚]
é¦™å±±å€, åŒ—å€, æ±å€

[æ–°ç«¹ç¸£]
äº”å³°é„‰, é—œè¥¿é®, å¯¶å±±é„‰, å³¨çœ‰é„‰, ç«¹åŒ—å¸‚, åŒ—åŸ”é„‰, èŠæ—é„‰, ç«¹æ±é®, æ©«å±±é„‰, å°–çŸ³é„‰, æ–°åŸ”é®, æ¹–å£é„‰, æ–°è±é„‰

[è‹—æ —ç¸£]
é€šéœ„é®, é ­å±‹é„‰, å…¬é¤¨é„‰, è‹—æ —å¸‚, å¾Œé¾é®, è¥¿æ¹–é„‰, é€ æ©‹é„‰, ä¸‰ç£é„‰, é ­ä»½å¸‚, ç«¹å—é®, å—åº„é„‰, ä¸‰ç¾©é„‰, å¤§æ¹–é„‰, æ³°å®‰é„‰, å“è˜­é®, ç…æ½­é„‰, éŠ…é‘¼é„‰, è‹‘è£¡é®

[è‡ºä¸­å¸‚]
é¾äº•å€, æ±å‹¢å€, å¤§é›…å€, å¤§è‚šå€, åŒ—å±¯å€, åŒ—å€, å¤ªå¹³å€, çƒæ—¥å€, æ±å€, è¥¿å±¯å€, è¥¿å€, æ¸…æ°´å€, ä¸­å€, éœ§å³°å€, æ½­å­å€, è±åŸå€, ç¥å²¡å€, å—å±¯å€, æ²™é¹¿å€, å¤§é‡Œå€, å—å€, å’Œå¹³å€, æ–°ç¤¾å€, çŸ³å²¡å€, åé‡Œå€, å¤§ç”²å€, å¤–åŸ”å€, å¤§å®‰å€, æ¢§æ£²å€

[å½°åŒ–ç¸£]
ç·šè¥¿é„‰, ä¼¸æ¸¯é„‰, é¹¿æ¸¯é®, å’Œç¾é®, æºªå·é„‰, ç”°ä¸­é®, äºŒæ°´é„‰, äºŒæ—é®, ç¦èˆˆé„‰, åŸ”é¹½é„‰, èŠ³è‹‘é„‰, ç§€æ°´é„‰, èŠ¬åœ’é„‰, å“¡æ—å¸‚, åŸ¤é ­é„‰, åŒ—æ–—é®, ç”°å°¾é„‰, ç¤¾é ­é„‰, å½°åŒ–å¸‚, å¤§æ‘é„‰, èŠ±å£‡é„‰, å¤§åŸé„‰, ç«¹å¡˜é„‰, æºªæ¹–é®, æ°¸é–é„‰, åŸ”å¿ƒé„‰

[å—æŠ•ç¸£]
ç«¹å±±é®, åé–“é„‰, æ°´é‡Œé„‰, ä¿¡ç¾©é„‰, é›†é›†é®, é¹¿è°·é„‰, è‰å±¯é®, å—æŠ•å¸‚, åœ‹å§“é„‰, ä¸­å¯®é„‰, ä»æ„›é„‰, åŸ”é‡Œé®, é­šæ± é„‰

[é›²æ—ç¸£]
å¤å‘é„‰, æ–—å—é®, åœŸåº«é®, å¤§åŸ¤é„‰, è™å°¾é®, å…ƒé•·é„‰, æ—å…§é„‰, è¿æ¡é„‰, è¥¿èºé®, æ–—å…­å¸‚, åŒ—æ¸¯é®, æ°´æ—é„‰, å£æ¹–é„‰, å››æ¹–é„‰, è¤’å¿ é„‰, å´™èƒŒé„‰, äºŒå´™é„‰, éº¥å¯®é„‰, æ±å‹¢é„‰, è‡ºè¥¿é„‰

[å˜‰ç¾©å¸‚]
æ±å€, è¥¿å€

[å˜‰ç¾©ç¸£]
æ–°æ¸¯é„‰, æºªå£é„‰, æ¢…å±±é„‰, ç«¹å´é„‰, å¤§æ—é®, å¤ªä¿å¸‚, æ°‘é›„é„‰, é˜¿é‡Œå±±é„‰, å¸ƒè¢‹é®, å…­è…³é„‰, ç¾©ç«¹é„‰, æ°´ä¸Šé„‰, ä¸­åŸ”é„‰, å¤§åŸ”é„‰, ç•ªè·¯é„‰, æ±çŸ³é„‰, æœ´å­å¸‚, é¹¿è‰é„‰

[è‡ºå—å¸‚]
æ­¸ä»å€, å®‰å®šå€, ä»å¾·å€, æ±å€, æ°¸åº·å€, å®‰å—å€, åŒ—å€, æ–°å¸‚å€, æ–°åŒ–å€, ä¸­è¥¿å€, å­¸ç”²å€, å·¦é®å€, é¾å´å€, å—å€, é¹½æ°´å€, ä¸‹ç‡Ÿå€, æ±å±±å€, å¾Œå£å€, æ–°ç‡Ÿå€, æŸ³ç‡Ÿå€, å…­ç”²å€, ç™½æ²³å€, å—åŒ–å€, è¥¿æ¸¯å€, å–„åŒ–å€, å¤§å…§å€, å±±ä¸Šå€, éº»è±†å€, å®‰å¹³å€, ä½³é‡Œå€, ä¸ƒè‚¡å€, ç‰äº•å€, å®˜ç”°å€, æ¥ è¥¿å€, é—œå»Ÿå€, å°‡è»å€, åŒ—é–€å€

[é«˜é›„å¸‚]
æ–°èˆˆå€, é¼“å±±å€, æ——æ´¥å€, å‰é‡‘å€, è‹“é›…å€, ä¸‰æ°‘å€, å‰é®å€, é¹½åŸ•å€, ç”°å¯®å€, ç‡•å·¢å€, å…§é–€å€, æ‰æ—å€, å°æ¸¯å€, é³³å±±å€, é³¥æ¾å€, å¤§æ¨¹å€, æ——å±±å€, ç¾æ¿ƒå€, å…­é¾œå€, èŒ„è£å€, æ¹–å…§å€, æ©‹é ­å€, æ¢“å®˜å€, å¤§ç¤¾å€, æ¡ƒæºå€, ç”²ä»™å€, èŒ‚æ—å€, ä»æ­¦å€, å²¡å±±å€, æ¥ æ¢“å€, é‚£ç‘ªå¤å€, é˜¿è“®å€, è·¯ç«¹å€, æ°¸å®‰å€, å¤§å¯®å€, æ—åœ’å€, å½Œé™€å€, å·¦ç‡Ÿå€

[å±æ±ç¸£]
å´é ‚é„‰, æ—é‚Šé„‰, æ±æ¸¯é®, å—å·é„‰, æ½®å·é®, ä½³å†¬é„‰, æ‹å±±é„‰, ç…å­é„‰, æ³°æ­¦é„‰, è¬å·’é„‰, æ–°åŸ¤é„‰, ä¾†ç¾©é„‰, æ˜¥æ—¥é„‰, æ‹å¯®é„‰, é¹½åŸ”é„‰, é«˜æ¨¹é„‰, é‡Œæ¸¯é„‰, ä¹å¦‚é„‰, ä¸‰åœ°é–€é„‰, éœ§è‡ºé„‰, æ†æ˜¥é®, ç‰¡ä¸¹é„‰, è»ŠåŸé„‰, æ»¿å·é„‰, ç‰çƒé„‰, å±æ±å¸‚, å…§åŸ”é„‰, é•·æ²»é„‰, ç‘ªå®¶é„‰, éºŸæ´›é„‰, ç«¹ç”°é„‰, æ–°åœ’é„‰, è¬ä¸¹é„‰

[å®œè˜­ç¸£]
å¤§åŒé„‰, å£¯åœé„‰, ç¤æºªé„‰, å®œè˜­å¸‚, å“¡å±±é„‰, äº”çµé„‰, å†¬å±±é„‰, ä¸‰æ˜Ÿé„‰, ç¾…æ±é®, é ­åŸé®, å—æ¾³é„‰, è˜‡æ¾³é®

[èŠ±è“®ç¸£]
ç‰é‡Œé®, è±æ¿±é„‰, å“æºªé„‰, å¯Œé‡Œé„‰, ç‘ç©—é„‰, èŠ±è“®å¸‚, ç§€æ—é„‰, æ–°åŸé„‰, å‰å®‰é„‰, å£½è±é„‰, è¬æ¦®é„‰, é³³æ—é®, å…‰å¾©é„‰

[è‡ºæ±ç¸£]
é•·æ¿±é„‰, å‘å—é„‰, å»¶å¹³é„‰, æˆåŠŸé®, é¹¿é‡é„‰, æ± ä¸Šé„‰, æ±æ²³é„‰, é—œå±±é®, æµ·ç«¯é„‰, é‡‘å³°é„‰, é”ä»é„‰, è‡ºæ±å¸‚, å¤ªéº»é‡Œé„‰, å¤§æ­¦é„‰, ç¶ å³¶é„‰, è˜­å¶¼é„‰

[æ¾æ¹–ç¸£]
æ¹–è¥¿é„‰, é¦¬å…¬å¸‚, ç™½æ²™é„‰, è¥¿å¶¼é„‰, æœ›å®‰é„‰, ä¸ƒç¾é„‰

ã€è¼¸å‡ºæ ¼å¼ã€‘ï¼š
- è‹¥åŒæ™‚ç¬¦åˆä¸Šè¿°å…©é …ï¼Œè¼¸å‡ºï¼š
  - "Towns": ä½¿ç”¨è€…è¼¸å…¥ä¸­æœ‰æ˜ç¢ºå‡ºç¾å‰‡æ“·å–ï¼Œå¦å‰‡ç‚º "null"
- è‹¥ä»»ä¸€æ¢ä»¶ä¸ç¬¦ï¼Œè¼¸å‡ºï¼š
  - Counties èˆ‡ Towns å‡è¨­ç‚º "null"
- åƒ…åŒ…å«ä¸€å€‹ JSON ç‰©ä»¶ï¼Œä¸èƒ½å¤šé¤˜æ–‡å­—ã€‚

ã€ç¯„ä¾‹ã€‘ï¼š
ä½¿ç”¨è€…è¼¸å…¥ï¼šã€Œè¬å·’ã€(æ„åœ–æ˜é¡¯æåŠã€Œè¬å·’é„‰ã€ï¼Œå±¬æ–¼ã€Œå±æ±ç¸£ã€çš„ä¸‰ç´šè¡Œæ”¿å€ã€‚è‡ªå‹•è£œå…¨å…¶æ‰€å±¬çš„ä¸€ã€äºŒç´šè¡Œæ”¿å€èˆ‡å–®ä½ã€‚)
output:{"Counties": "å±æ±ç¸£", "Towns": "è¬å·’é„‰"}

ä½¿ç”¨è€…è¼¸å…¥ï¼šã€Œå°ä¸­ã€(æ„åœ–æ˜é¡¯æåŠã€Œå°ä¸­å¸‚ã€ï¼Œå±¬æ–¼ä¸€ã€äºŒç´šè¡Œæ”¿å€ã€‚åƒè€ƒè³‡æ–™åº«è‡ºä¸­å¸‚æ­£æ¥·åç¨±ã€‚)
output:{"Counties": "è‡ºä¸­å¸‚", "Towns": "null"}

ä½¿ç”¨è€…è¼¸å…¥ï¼šã€Œå±æ±ç¸£é«˜é›„ã€(æ„åœ–æ˜é¡¯æåŠã€Œå±æ±ç¸£ã€ï¼Œä½†ã€Œé«˜é›„ã€ä¸¦éå…¶æ‰€å±¬çš„ä¸‰ç´šè¡Œæ”¿å€ï¼Œå› æ­¤ç„¡æ•ˆã€‚)
output:{"Counties": "å±æ±ç¸£", "Towns": "null"}

ä½¿ç”¨è€…è¼¸å…¥ï¼šã€Œé‡Œè¬å€æœ‰åœæ°´å—ã€(æ„åœ–æ˜é¡¯æåŠã€Œé‡Œè¬å€ã€ï¼Œä½†ã€Œé‡Œè¬ã€ä¸¦éæœ‰æ•ˆçš„åœ°åï¼Œç„¡æ³•å°æ‡‰åˆ°ä»»ä½•ä¸€ã€äºŒç´šæˆ–ä¸‰ç´šè¡Œæ”¿å€ã€‚)
output:{"Counties": "null", "Towns": "null"}

ä½¿ç”¨è€…è¼¸å…¥ï¼šã€Œæˆ‘æƒ³æŸ¥åœæ°´ã€(æ„åœ–æ˜é¡¯æåŠåœæ°´ï¼Œä½†æ²’æœ‰æ˜ç¢ºçš„åœ°åã€‚)
output:{"Counties": "null", "Towns": "null"}"""

        payload = {
            "model":    MODEL,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user",   "content": prompt}
            ],
            "stream": False
        }
        resp = requests.post(API_URL, headers=HEADERS, json=payload)
        resp.raise_for_status()
        data = resp.json()
        return data["choices"][0]["message"]["content"]

# æ™®é€šå°è©±æ©Ÿå™¨äºº
class NormalLLM(ClassifierLLM):  # å¯ç¹¼æ‰¿åŒæ¨£åº•å±¤
    def _call(self, prompt: str, stop=None) -> str:
        payload = {
            "model":    MODEL,
            "messages": [
                {"role": "system", "content": 'æ ¹æ“šç¾æœ‰è³‡è¨Šï¼Œä½¿ç”¨ä¸­æ–‡å›ç­”ä½¿ç”¨è€…æå‡ºçš„å•é¡Œã€‚'},
                {"role": "user",   "content": prompt}
            ],
            "stream": False
        }
        resp = requests.post(API_URL, headers=HEADERS, json=payload)
        resp.raise_for_status()
        data = resp.json()
        return data["choices"][0]["message"]["content"]


#==========================
question_classifier = LLMChain(
    llm=ClassifierLLM(),
    prompt=PromptTemplate(
        input_variables=["text"],
        template="""
è«‹åˆ¤æ–·ä¸‹é¢é€™æ®µä½¿ç”¨è€…è¼¸å…¥ï¼Œæ˜¯å¦ç‚ºã€Œæå‡ºå•é¡Œã€ï¼Ÿ
- å¦‚æœæ˜¯åœ¨æå•ï¼Œå›è¦†ã€Œæ˜¯ã€
- å¦‚æœä¸æ˜¯æå•ï¼ˆé–’èŠã€é™³è¿°ç­‰ï¼‰ï¼Œå›è¦†ã€Œå¦ã€
ä¸”å›è¦†ä¸­åƒ…åŒ…å«ä¸€å€‹å­—ï¼Œä¸èƒ½å¤šé¤˜æ–‡å­—ã€‚

ä½¿ç”¨è€…ï¼š{text}"""
    )
)

can_answer_chain = LLMChain(
    llm=ClassifierLLM(),
    prompt=PromptTemplate(
        input_variables=["question", "docs"],
        template="""
ä¸‹é¢æ˜¯å¾æœ¬åœ°çŸ¥è­˜åº«æª¢ç´¢åˆ°çš„æ–‡ä»¶ç‰‡æ®µï¼š
{docs}

è«‹æ ¹æ“šä¸Šè¿°ç‰‡æ®µï¼Œåˆ¤æ–·èƒ½å¦å›ç­”ä»¥ä¸‹ç”¨æˆ¶æå•ï¼š
ã€Œ{question}ã€
- å¦‚æœèƒ½ï¼Œåƒ…å›ã€Œæ˜¯ã€
- å¦‚æœä¸èƒ½ï¼Œåƒ…å›ã€Œå¦ã€
ä¸”å›è¦†ä¸­åƒ…åŒ…å«ä¸€å€‹å­—ï¼Œä¸è¦å…¶å®ƒå¤šé¤˜æ–‡å­—ã€‚"""
    ),
    output_key="verdict"
)

wrong_question_classifier = LLMChain(
    llm=ClassifierLLM(),
    prompt=PromptTemplate(
        input_variables=["text"],
        template="""
è«‹åˆ¤æ–·ä¸‹é¢é€™æ®µä½¿ç”¨è€…è¼¸å…¥çš„å•é¡Œï¼Œæ˜¯å¦èˆ‡æ°´å‹™æ¥­å‹™ç›¸é—œï¼Ÿ
- å¦‚æœæ˜¯ï¼Œå›è¦†ã€Œæ˜¯ã€
- å¦‚æœä¸æ˜¯ï¼ˆé–’èŠã€ç§‘æ™®ã€é™³è¿°ã€éæ°´å‹™æ¥­å‹™ç›¸é—œç­‰ï¼‰ï¼Œå›è¦†ã€Œå¦ã€
ä¸”å›è¦†ä¸­åƒ…åŒ…å«ä¸€å€‹å­—ï¼Œä¸èƒ½å¤šé¤˜æ–‡å­—ã€‚

ä½¿ç”¨è€…ï¼š{text}
"""
    )
)
#==========================

#llm_retrieve_chain = LLMChain(
#    llm=RetrieveLLM(),
#    prompt=PromptTemplate(
#        input_variables=["question", "docs"],
#        template="""ä¸‹é¢æ˜¯å¾æœ¬åœ°çŸ¥è­˜åº«æª¢ç´¢åˆ°çš„æ–‡ä»¶ç‰‡æ®µï¼š
#{docs}
#
#è«‹æ ¹æ“šä¸Šè¿°ç‰‡æ®µï¼Œè«‹é¸æ“‡ä¸€å€‹æœ€èƒ½è§£ç­”ä½¿ç”¨è€…çš„ç–‘å•ä¹‹æ–‡ä»¶ç‰‡æ®µï¼š
#ã€Œ{question}ã€
#
#ä¸”å›è¦†ä¸­åƒ…åŒ…å«å…¶ä¸­ä¸€å€‹æ–‡ä»¶ç‰‡æ®µçš„å…§å®¹ï¼Œä¸è¦å°‡ç·¨è™Ÿèˆ‡æ¨™é¡Œä¸€åŒè¼¸å‡ºï¼Œä»¥åŠå…¶å®ƒå¤šé¤˜æ–‡å­—ã€‚"""
#    ),
#    output_key="verdict"
#)
llm_retrieve_chain = LLMChain(
    llm=RetrieveLLM(),
    prompt=PromptTemplate(
        input_variables=["question", "docs"],
        template="""ä¸‹é¢æ˜¯å¾æœ¬åœ°çŸ¥è­˜åº«æª¢ç´¢åˆ°çš„æ–‡ä»¶ç‰‡æ®µï¼š
{docs}

è«‹æ ¹æ“šä¸Šè¿°ç‰‡æ®µï¼Œè«‹é¸æ“‡ä¸€å€‹æœ€èƒ½è§£ç­”ä½¿ç”¨è€…çš„ç–‘å•ä¹‹æ–‡ä»¶ç‰‡æ®µï¼š
ã€Œ{question}ã€

åƒ…å›è¦†è§£ç­”æ–‡ä»¶ç‰‡æ®µæ‰€å±¬çš„æ•´æ•¸ç·¨è™Ÿï¼Œä¸è¦å°‡æ¨™é¡Œã€å…§å®¹æˆ–ç¬¦è™Ÿä¸€åŒè¼¸å‡ºï¼Œä»¥åŠå…¶å®ƒå¤šé¤˜æ–‡å­—ã€‚"""
    ),
    output_key="verdict"
)

emotion_classifier = LLMChain(
    llm=EmotionLLM(),
    prompt=PromptTemplate(
        input_variables=["text"],
        template="""ä½¿ç”¨è€…ï¼š{text}"""
    )
)


location_outage_classifier = LLMChain(
    llm=LocationOutageLLM(),
    prompt=PromptTemplate(
        input_variables=["text"],
        template="""ä½¿ç”¨è€…ï¼š{text}"""
    )
)


status_classifier = LLMChain(
    llm=StatusLLM(),
    prompt=PromptTemplate(
        input_variables=["text"],
        template="""å°è©±ç´€éŒ„ï¼š{text}
        
ä½¿ç”¨è€…æœ€æ–°è¨Šæ¯ï¼š{user_message}"""
    )
)

normal_classifier = LLMChain(
    llm=NormalLLM(),
    prompt=PromptTemplate(
        input_variables=["text", "info"],
        template="""
ä½¿ç”¨è€…ï¼š{text}ã€‚
è³‡è¨Šï¼š{info}ã€‚
ç¾åœ¨æ™‚é–“ï¼š{time}ã€‚
"""
    )
)


CATEGORY_MAP = {
    1: "é›»å­å¸³å–®ã€ç°¡è¨Šå¸³å–®åŠé€šçŸ¥æœå‹™",
    2: "å¸³å–®èˆ‡ç¹³è²»ç®¡ç†",
    3: "ç”¨æˆ¶å¸³æˆ¶èˆ‡ç”¨æ°´è¨­å‚™ç®¡ç†",
    4: "æ°´è³ªã€æ·¨æ°´èˆ‡ç”Ÿæ´»æ‡‰ç”¨",
    5: "æ±¡æ°´ä¸‹æ°´é“èˆ‡æ±¡æ°´ä½¿ç”¨è²»",
    6: "ç·Šæ€¥åœæ°´ã€è¨ˆç•«åœæ°´èˆ‡æ‡‰è®Š",
    7: "æ°´åƒ¹æ”¿ç­–èˆ‡äº‹æ¥­ç¶“ç‡Ÿ",
    8: "Appï¼ç¶²ç«™ä½¿ç”¨èˆ‡éš±ç§æ”¿ç­–",
}


def generate_water_off_notification(no=None, start_date=None, end_date=None, start_time=None, end_time=None, 
                                  water_off_region=None, water_off_reason=None, water_off_number=None, 
                                  contact=None, pressure_down_region=None, pressure_down_reason=None, 
                                  pressure_down_number=None):
    """
    ç”Ÿæˆåœæ°´è³‡è¨Šé€šçŸ¥çš„markdownæ¨¡æ¿
    
    åƒæ•¸:
    - no: ç·¨è™Ÿ (å¯é¸)
    - start_date: é–‹å§‹æ—¥æœŸ (æ ¼å¼: YYYY-MM-DD æˆ–ä¸­æ–‡) (å¯é¸)
    - end_date: çµæŸæ—¥æœŸ (æ ¼å¼: YYYY-MM-DD æˆ–ä¸­æ–‡) (å¯é¸)
    - start_time: é–‹å§‹æ™‚é–“ (æ ¼å¼: HH:MM æˆ–ä¸­æ–‡) (å¯é¸)
    - end_time: çµæŸæ™‚é–“ (æ ¼å¼: HH:MM æˆ–ä¸­æ–‡) (å¯é¸)
    - water_off_region: åœæ°´å€åŸŸ (å¯é¸)
    - water_off_reason: åœæ°´åŸå›  (å¯é¸)
    - water_off_number: åœæ°´æˆ¶æ•¸ (å¯é¸)
    - contact: è¯çµ¡é›»è©± (å¯é¸)
    - pressure_down_region: æ¸›å£“å€åŸŸ (å¯é¸)
    - pressure_down_reason: æ¸›å£“åŸå›  (å¯é¸)
    - pressure_down_number: æ¸›å£“æˆ¶æ•¸ (å¯é¸)
    """
    
    # æ ¼å¼åŒ–æ—¥æœŸæ™‚é–“
    formatted_start_date = ''
    formatted_end_date = ''
    formatted_start_time = ''
    formatted_end_time = ''
    
    if start_date:
        if len(start_date) == 10 and start_date.count('-') == 2:
            formatted_start_date = start_date.replace('-', 'å¹´', 1).replace('-', 'æœˆ') + 'æ—¥'
        else:
            formatted_start_date = start_date
            
    if end_date:
        if len(end_date) == 10 and end_date.count('-') == 2:
            formatted_end_date = end_date.replace('-', 'å¹´', 1).replace('-', 'æœˆ') + 'æ—¥'
        else:
            formatted_end_date = end_date
    
    if start_time and ':' in start_time:
        hour, minute = start_time.split(':')
        formatted_start_time = f"ä¸Šåˆ{hour}:{minute}" if int(hour) < 12 else f"ä¸‹åˆ{int(hour)-12 if int(hour) > 12 else hour}:{minute}"
    elif start_time:
        formatted_start_time = start_time
    
    if end_time and ':' in end_time:
        hour, minute = end_time.split(':')
        formatted_end_time = f"ä¸Šåˆ{hour}:{minute}" if int(hour) < 12 else f"ä¸‹åˆ{int(hour)-12 if int(hour) > 12 else hour}:{minute}"
    elif end_time:
        formatted_end_time = end_time
    
    template = f"""## åœæ°´é€šçŸ¥"""

    # æ·»åŠ ç·¨è™Ÿï¼ˆå¦‚æœæœ‰ï¼‰
    if no:
        template += f"ï¼ˆç·¨è™Ÿï¼š[{no}](https://web.water.gov.tw/wateroffmap/map/view/{no})ï¼‰"
        
    # æ·»åŠ æ™‚é–“è³‡è¨Šï¼ˆå¦‚æœæœ‰ï¼‰
    if formatted_start_date or formatted_end_date or formatted_start_time or formatted_end_time:
        template += f"""

### ğŸ“… åœæ°´æ™‚é–“"""
        
        if formatted_start_date or formatted_end_date:
            template += f"\n- **æ—¥æœŸ**ï¼š"
            if formatted_start_date and formatted_end_date:
                template += f"{formatted_start_date} è‡³ {formatted_end_date}"
            elif formatted_start_date:
                template += f"{formatted_start_date} èµ·"
            else:
                template += f"è‡³ {formatted_end_date}"
                
        if formatted_start_time or formatted_end_time:
            template += f"\n- **æ™‚é–“**ï¼š"
            if formatted_start_time and formatted_end_time:
                template += f"{formatted_start_time} è‡³ {formatted_end_time}"
            elif formatted_start_time:
                template += f"{formatted_start_time} èµ·"
            else:
                template += f"è‡³ {formatted_end_time}"

    # æ·»åŠ å½±éŸ¿å€åŸŸï¼ˆå¦‚æœæœ‰ï¼‰
    if water_off_region:
        template += f"""

### ğŸ“ å½±éŸ¿å€åŸŸ
{water_off_region.replace("~", "è‡³")}"""

    # æ·»åŠ åœæ°´åŸå› ï¼ˆå¦‚æœæœ‰ï¼‰
    if water_off_reason:
        template += f"""

### ğŸ”§ åœæ°´åŸå› 
{water_off_reason}"""

    # æ·»åŠ å½±éŸ¿æˆ¶æ•¸ï¼ˆå¦‚æœæœ‰ï¼‰
    if water_off_number is not None:
        template += f"""

### ğŸ“Š å½±éŸ¿æˆ¶æ•¸
**{water_off_number:,}æˆ¶**"""

    # å¦‚æœæœ‰æ¸›å£“è³‡è¨Šï¼ŒåŠ å…¥æ¸›å£“éƒ¨åˆ†
    if pressure_down_region or pressure_down_reason or (pressure_down_number is not None and pressure_down_number > 0):
        template += f"""

### âš¡ æ¸›å£“å½±éŸ¿"""
        
        if pressure_down_region:
            template += f"\n- **æ¸›å£“å€åŸŸ**ï¼š{pressure_down_region}"
            
        if pressure_down_reason:
            template += f"\n- **æ¸›å£“åŸå› **ï¼š{pressure_down_reason}"
            
        if pressure_down_number is not None:
            template += f"\n- **æ¸›å£“æˆ¶æ•¸**ï¼š**{pressure_down_number:,}æˆ¶**"

    # æ·»åŠ è¯çµ¡é›»è©±ï¼ˆå¦‚æœæœ‰ï¼‰
    if contact:
        template += f"""

### â˜ï¸ è¯çµ¡é›»è©±
**{contact}**"""

    # æ·»åŠ æ³¨æ„äº‹é …
    template += f"""

---

"""

    return template

# å®šç¾©æ¨¡æ¿é ­éƒ¨
template_title = """# ğŸš° [ä¾›æ°´æŸ¥è©¢](https://web.water.gov.tw/wateroffmap/map)

"""

# å®šç¾©æ¨¡æ¿å°¾éƒ¨
template_note = """## âš ï¸ é‡è¦æ³¨æ„äº‹é …

1. **å„²æ°´æº–å‚™**ï¼šåœæ°´ç¯„åœå…§ç”¨æˆ¶è«‹è‡ªè¡Œå„²æ°´å‚™ç”¨
2. **å®‰å…¨æé†’**ï¼šåœæ°´æœŸé–“è«‹æ…é˜²ç«æºï¼Œé—œé–‰æŠ½æ°´æ©Ÿé›»æº
3. **é˜²æ±¡æŸ“æªæ–½**ï¼šå»ºç¯‰ç‰©è‡ªä¾†æ°´é€²æ°´å£ä½æ–¼åœ°é¢çš„ç”¨æˆ¶ï¼Œè«‹é—œé–‰ç¸½è¡¨å‰åˆ¶æ°´é–¥
4. **å¾©æ°´æ™‚é–“**ï¼šç®¡ç·šæœ«ç«¯åŠé«˜åœ°å€åŸŸå¯èƒ½å»¶é²å¾©æ°´
5. **é€²åº¦æŸ¥è©¢**ï¼šå¯è‡³[åœæ°´æŸ¥è©¢ç³»çµ±](https://web.water.gov.tw/wateroffmap/map)æŸ¥è©¢åœå¾©æ°´é€²åº¦"""


class WaterGPTClient:
    def __init__(self):
        self.shared = {"last_docs": []}
        self.headers = HEADERS
        self.embedding_url = EMBEDDING_URL
        # ä½¿ç”¨è€…æ˜¯å¦è©¢å•åœæ°´ç›¸é—œæ——æ¨™
        self.water_outage_flag = False

        # æ©Ÿå™¨äººç‹€æ…‹
        #  READYï¼šæº–å‚™å°±ç·’
        #  OUTAGEï¼šåœæ°´æŸ¥è©¢
        #  RAGï¼šRAGæŸ¥è©¢
        self.STATUS = "READY"  # æ©Ÿå™¨äººç‹€æ…‹
        #self.OUTAGE_COUNTY = ""  # åœæ°´æŸ¥è©¢ç¸£å¸‚
        #self.OUTAGE_TOWNS = ""  # åœæ°´æŸ¥è©¢é„‰é®å¸‚å€

    # ç§»é™¤WebSocketé€£æ¥æ–¹æ³•ï¼Œæ”¹ç‚ºç›´æ¥ä½¿ç”¨requests
    async def ask(self, text, history, quick_replies=[]):
        text = text.strip()
        user_history = history.copy()  # è¤‡è£½æ­·å²å°è©±ï¼Œé¿å…ä¿®æ”¹åŸå§‹è³‡æ–™

        user_history.append({"role": "user", "content": text})

        history_str = []
        for entry in history:
            role = entry['role']
            content = entry['content']
            if role == 'system':
                continue  # è·³é system çš„å…§å®¹
            history_str.append(f"{role}:{content}")

        # ç”¨æ›è¡Œç¬¦é€£æ¥çµæœ
        formatted_string = '\n'.join(history_str)
        print(formatted_string)

        #print(history)
        status = status_classifier.predict(text=formatted_string, user_message=text).strip()
        status = status.replace("json", "").replace("```", "").replace("\n", "").replace(" ", "")

        # æƒ…ç·’åˆ¤æ–·
        emotion = emotion_classifier.predict(text=text).strip()

        if emotion == "anger":
            result = "éå¸¸æŠ±æ­‰è®“æ‚¨æ„Ÿåˆ°ä¸æ»¿æ„ï¼Œæˆ‘æœƒç›¡å¿«ç‚ºæ‚¨æœå‹™ã€‚"
            return result, history # è¿”å›æƒ…ç·’å›æ‡‰, ä¸æ–°å¢æ­·å²å°è©±
        
        print(status)
        status = json.loads(status)

        if status['status'] == "RAG":
            # ç›´æ¥ä½¿ç”¨requestsç™¼é€POSTè«‹æ±‚
            payload = {
                "request": text,
                "top_k": 5
            }
            response = requests.post(self.embedding_url, headers=self.headers, json=payload)
            response.raise_for_status()
            data = response.json()
            docs = data["response"]

            #if not docs:
            #    return "âŒ æ²’æœ‰æ‰¾åˆ°ç›¸é—œæ–‡ä»¶ã€‚", history

            # æ›´æ–°sharedå­—å…¸ï¼Œä¿æŒèˆ‡åŸä»£ç¢¼ç›¸å®¹
            self.shared["last_docs"] = docs

            docs_text = "\n\n".join(
                f"{i+1} æ¨™é¡Œï¼š{d['title']}\nå…§å®¹ï¼š{d['content']}"
                for i, d in enumerate(docs)
            )

            # å°‡æ¯ä¸€å€‹æ–‡ä»¶æ¨™é¡ŒåŠ å…¥å¿«æ·è¨Šæ¯
            for d in docs:
                quick_replies.append(d['title'])

            #print(docs)
            # åˆ¤æ–·æ˜¯å¦èƒ½å›ç­”
            answerable = can_answer_chain.predict(
                question=text,
                docs=docs_text
            ).strip()

            if answerable == "æ˜¯":
                result = llm_retrieve_chain.predict(
                    question=text,
                    docs=docs_text
                ).strip()

                #try:
                result = docs[int(result)-1]['content'] 
                #except:
                #    return "âŒ ç„¡æ³•ç²å–æ­£ç¢ºçš„æ–‡ä»¶ç·¨è™Ÿï¼Œè«‹ç¨å¾Œå†è©¦ã€‚", history
            
                user_history.append({"role": "assistant", "content": "(RAGå…§å®¹)"})

                return result, user_history
            else:
                # åˆ¤æ–·æ˜¯å¦ç‚ºæ°´å‹™ç›¸é—œå•é¡Œ
                wrong_question = wrong_question_classifier.predict(text=text).strip()
                if wrong_question == "æ˜¯":
                    return "âœ” æˆ‘å¯ä»¥å¹«ä½ æ¥æ´½å°ˆäºº", history # ä¸æ–°å¢æ­·å²å°è©±
                else:
                    return "âœ˜ å¾ˆæŠ±æ­‰ï¼Œè«‹è©¢å•èˆ‡å°ç£è‡ªä¾†æ°´å…¬å¸ç›¸é—œä¹‹å•é¡Œå–”!", history # ä¸æ–°å¢æ­·å²å°è©±
                
        if status['status'] == "OUTAGE":
            location_outage_str = location_outage_classifier.predict(text=text).strip()
            location_outage_str = location_outage_str.replace("json", "").replace("```", "").replace("\n", "").replace(" ", "")

            try:
                print(location_outage_str)
                location = json.loads(location_outage_str)
                water_affected_counties = location['Counties']
                water_affected_towns = location['Towns']

                if water_affected_towns == "null":
                    water_affected_towns = None

                if water_affected_counties == "null":
                    user_history.append({"role": "assistant", "content": "è«‹è¼¸å…¥è©³ç´°åœ°å€ï¼Œä¾‹å¦‚ï¼šå°ä¸­å¸‚åŒ—å€"})
                    return "è«‹è¼¸å…¥è©³ç´°åœ°å€ï¼Œä¾‹å¦‚ï¼šå°ä¸­å¸‚åŒ—å€", user_history

                response = requests.get(WATER_OUTAGE_URL, params={"affectedCounties": water_affected_counties, "affectedTowns": water_affected_towns, "query": "name"})
                
                response = response.json()

                if response.get("message") == "success":
                    response = response.get("result")
                else:
                    return "ä¼ºæœå™¨å¿™ç¢Œä¸­ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚", history # ä¸æ–°å¢æ­·å²å°è©±

                output = ""
                for i in response:
                    output += generate_water_off_notification(
                        no=i["no"],
                        start_date=i["startDate"],
                        end_date=i["endDate"],
                        start_time=i["startTime"],
                        end_time=i["endTime"],
                        water_off_region=i["waterOffRegion"],
                        water_off_reason=i["waterOffReason"],
                        water_off_number=i["waterOffNumber"],
                        contact=i["contact"],
                        pressure_down_region=i["pressureDownRegion"],
                        pressure_down_reason=i["pressureDownReason"],
                        pressure_down_number=i["pressureDownNumber"],
                    )
                user_history.append({"role": "assistant", "content": "(å›æ‡‰åœæ°´å…§å®¹)"})
                if output == "":
                    if water_affected_towns != None:
                        return f"âœ… ç›®å‰{water_affected_counties}{water_affected_towns}åœ°å€ç„¡åœæ°´è³‡è¨Šï¼Œå¦‚æœ‰ç”¨æ°´å•é¡Œè«‹æ’¥æœ¬å…¬å¸24å°æ™‚å…ä»˜è²»å®¢æœå°ˆç·šã€1910ã€ã€‚", user_history
                    else:
                        return f"âœ… ç›®å‰{water_affected_counties}åœ°å€ç„¡åœæ°´è³‡è¨Šï¼Œå¦‚æœ‰ç”¨æ°´å•é¡Œè«‹æ’¥æœ¬å…¬å¸24å°æ™‚å…ä»˜è²»å®¢æœå°ˆç·šã€1910ã€ã€‚", user_history
                
                return template_title + output + template_note, user_history

            except json.JSONDecodeError as e:
                print(f"Error decoding JSON: {e}")
                print(f"Problematic string that caused error: ---{e.doc}---") # e.doc æ˜¯å°è‡´éŒ¯èª¤çš„åŸå§‹å­—ä¸²
                return "æ‚¨è¼¸å…¥çš„è³‡è¨Šæœ‰èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚", history # ä¸æ–°å¢æ­·å²å°è©±

        return "âœ˜ é€™çœ‹èµ·ä¾†ä¸æ˜¯ä¸€å€‹å•é¡Œï¼Œè«‹è¼¸å…¥æ°´å‹™ç›¸é—œæå•ã€‚", history # ä¸æ–°å¢æ­·å²å°è©±

# ç§»é™¤åŸä¾†çš„handle_wså‡½æ•¸ï¼Œæ”¹ç‚ºç›´æ¥è«‹æ±‚çš„å‡½æ•¸
async def get_embedding_data(text, top_k=5):
    payload = {
        "request": text,
        "top_k": top_k
    }
    response = requests.post(EMBEDDING_URL, headers=HEADERS, json=payload)
    response.raise_for_status()
    data = response.json()
    return data["response"]


async def main():
    print("Bot readyï¼Œè¼¸å…¥ exit é›¢é–‹ã€‚")

    shared = {"last_docs": []}

    while True:
        text = await asyncio.to_thread(input, "> ")
        text = text.strip()
        if text.lower() in ("exit", "quit"):
            break

        verdict = question_classifier.predict(text=text).strip()
        print(f"[åˆ†é¡çµæœ] {verdict}")

        if verdict != "æ˜¯":
            print("âœ˜ é€™çœ‹èµ·ä¾†ä¸æ˜¯ä¸€å€‹å•é¡Œï¼Œè«‹éš¨æ™‚è¼¸å…¥æ°´å‹™ç›¸é—œæå•ã€‚")
            continue

        # ä½¿ç”¨requestsç›´æ¥ç²å–è³‡æ–™
        try:
            docs = await get_embedding_data(text)
            shared["last_docs"] = docs

            print(f"âŸ³ æ‰¾åˆ° {len(docs)} ç¯‡æœ€ç›¸é—œæ–‡ä»¶ï¼š")
            for i in docs:
                print(f"[score{i['confidence']}ï½œé¡åˆ¥{i['category']}ï½œ{CATEGORY_MAP[int(i['category'])]}] {i['title']}")
        except Exception as e:
            print(f"âŒ ç²å–åµŒå…¥æ•¸æ“šæ™‚å‡ºéŒ¯: {e}")
            continue

        if not docs:
            print("âŒ æ²’æœ‰æ‰¾åˆ°ç›¸é—œæ–‡ä»¶ã€‚")
            continue

        docs_text = "\n\n".join(
            f"[{i+1}] æ¨™é¡Œï¼š{d['title']}\nå…§å®¹ï¼š{d['content']}"
            for i, d in enumerate(docs)
        )

        answerable = can_answer_chain.predict(
            question=text,
            docs=docs_text
        ).strip()

        if answerable == "æ˜¯":
            result = llm_retrieve_chain.predict(
                question=text,
                docs=docs_text
            ).strip()
            print(result)
            continue

        wrong_question = wrong_question_classifier.predict(text=text).strip()
        if wrong_question == "æ˜¯":
            print("âœ” æˆ‘å¯ä»¥å¹«ä½ æ¥æ´½å°ˆäºº")
        else:
            print("âœ˜ å¾ˆæŠ±æ­‰ï¼Œè«‹è©¢å•èˆ‡å°ç£è‡ªä¾†æ°´å…¬å¸ç›¸é—œä¹‹å•é¡Œå–”!")

if __name__ == "__main__":
    pass

# WaterGPTClient æ¸¬è©¦
'''
async def example():
    # å»ºç«‹å®¢æˆ¶ç«¯
    client = WaterGPTClient()
    
    # æå•
    response = await client.ask("è«‹å•å¦‚ä½•ç¹³æ°´è²»ï¼Ÿ")
    print(f"å›ç­”: {response}")
    
    # å¯ä»¥å¤šæ¬¡æå•
    response = await client.ask("æ°´è³ªæª¢æ¸¬æ¨™æº–æ˜¯ä»€éº¼ï¼Ÿ")
    print(f"å›ç­”: {response}")

# é‹è¡Œç¯„ä¾‹
# asyncio.run(example())
'''